{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d02722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678d2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c97deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34bfae8",
   "metadata": {},
   "source": [
    "### Define functions for use during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c26c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_count_vals(df, colname, threshold):\n",
    "    # Determine which values to replace if counts are less than ...?\n",
    "    counts = df[colname].value_counts()\n",
    "    replace_list = list(counts[counts < threshold].index)\n",
    "\n",
    "    # Replace in dataframe\n",
    "    for item in replace_list:\n",
    "       df[colname] = df[colname].replace(item,\"Other\")\n",
    "    \n",
    "    # Check to make sure binning was successful\n",
    "    df[colname].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6966a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_hot(df, y_col):\n",
    "    # Create a list of columns that are 'object' type\n",
    "    obj_cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(df[obj_cat]))\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(obj_cat)\n",
    "    \n",
    "    # Merge one-hot encoded features and drop the originals\n",
    "    df = df.merge(encode_df, left_index=True, right_index=True)\n",
    "    df = df.drop(obj_cat,1)\n",
    "    \n",
    "    # Split our preprocessed data into our features and target arrays\n",
    "    y = df[y_col].values\n",
    "    df.drop(columns=[y_col], inplace=True)\n",
    "    X = df.values\n",
    "    print(f\"merged df.shape()={df.shape}\")\n",
    "    \n",
    "    return df, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaebfc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_scatter_plots(df):\n",
    "    colnames = ['APPLICATION_TYPE', \n",
    "        'AFFILIATION', \n",
    "        'CLASSIFICATION', \n",
    "        'USE_CASE', \n",
    "        'ORGANIZATION', \n",
    "        'INCOME_AMT',\n",
    "        'SPECIAL_CONSIDERATIONS', \n",
    "        'ASK_AMT',\n",
    "    ]\n",
    "    #fig, axes = plt.subplots(nrows=8, ncols=8, figsize=(24,24))\n",
    "    for xx in range(0,8):\n",
    "        for yy in range(xx+1,8):\n",
    "            #if xx == yy:\n",
    "            #    continue\n",
    "            titlestring = f\"x={colnames[xx]} vs. y={colnames[yy]}\"\n",
    "            #df.plot.scatter(ax=axes[xx,yy], x=colnames[xx], y=colnames[yy], title=titlestring, c=df['IS_SUCCESSFUL'], s=(df['ASK_AMT']*20), colormap='winter')\n",
    "            df.plot.scatter(\n",
    "                figsize=(6,6),\n",
    "                x=colnames[xx], \n",
    "                y=colnames[yy], \n",
    "                title=titlestring,\n",
    "                xlabel=colnames[xx],\n",
    "                ylabel=colnames[yy],\n",
    "                c=df['IS_SUCCESSFUL'], \n",
    "                s=(df['ASK_AMT']*50), \n",
    "                colormap='winter'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db688177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_scale(scaler):\n",
    "    # Scale the data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d6a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, layers):\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    first = True\n",
    "    for layer in layers:\n",
    "        if first:\n",
    "            first = False\n",
    "            nn.add(tf.keras.layers.Dense(units=layer['units'], activation=layer['act'], input_dim=inputs))\n",
    "        else:\n",
    "            nn.add(tf.keras.layers.Dense(units=layer['units'], activation=layer['act']))\n",
    "\n",
    "    print(nn.summary())\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160cdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(model, X_train, y_train, n_epochs, checkpoint_dir):\n",
    "    # Create a callback that saves the model's weights every epoch\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    \n",
    "    # Define the checkpoint path and filenames\n",
    "    os.makedirs(\"checkpoints_opt\",exist_ok=True)\n",
    "    #checkpoint_file = f\"weights.{epoch:02d}.hdf5\"\n",
    "    #checkpoint_path = f\"checkpoints_opt/weights.{epoch:02d}.hdf5\"\n",
    "    checkpoint_path = \"checkpoints_opt/weights_2.{epoch:02d}.hdf5\"\n",
    "    \n",
    "    cp_callback_opt = ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        period=5)\n",
    "\n",
    "    # Normally we use 'save_freq', but it behaves strangely, and I could not get\n",
    "    # it to save every 5 epochs. The 'period' param is now deprecated, but it works.\n",
    "        #save_freq='epoch')\n",
    "        \n",
    "    fit_model = model.fit(X_train, y_train, epochs=n_epochs, callbacks=[cp_callback_opt])\n",
    "    return fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba1a49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_keras_tuner(X_train, y_train, n_epochs, validation_data):\n",
    "    # Create a `Hyperband()` tuner instance\n",
    "    tuner = kt.Hyperband(\n",
    "        create_tuner_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_epochs=50,\n",
    "        hyperband_iterations=2,\n",
    "        overwrite=True)\n",
    "\n",
    "    # Run the kerastuner search for best hyperparameters\n",
    "    tuner.search(X_train, y_train, epochs=n_epochs, validation_data=validation_data)\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05614f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_to_int(range_str):\n",
    "    if range_str == \"0\":\n",
    "        return 0\n",
    "    elif range_str == \"1-9999\":\n",
    "        return 9_999 \n",
    "    elif range_str == \"10000-24999\":\n",
    "        return 24_999 \n",
    "    elif range_str == \"25000-99999\":\n",
    "        return 99_999 \n",
    "    elif range_str == \"100000-499999\":\n",
    "        return 499_999 \n",
    "    elif range_str == \"500000-1000000\":\n",
    "        return 1_000_000 \n",
    "    elif range_str == \"500000-1M\":\n",
    "        return 1_000_000 \n",
    "    elif range_str == \"1M-5M\":\n",
    "        return 5_000_000\n",
    "    elif range_str == \"5M-10M\":\n",
    "        return 10_000_000 \n",
    "    elif range_str == \"10M-50M\":\n",
    "        return 50_000_000\n",
    "    elif range_str == \"50M+\":\n",
    "        return 100_000_000 \n",
    "    else:\n",
    "        return 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609deba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_ask(ask):\n",
    "    if ask == 0:\n",
    "        return \"0\"\n",
    "    elif ask < 9999:\n",
    "        return \"1-9999\"\n",
    "    elif ask < 24999:\n",
    "        return \"10000-24999\"\n",
    "    elif ask < 99999:\n",
    "        return \"25000-99999\"\n",
    "    elif ask < 499999:\n",
    "        return \"100000-499999\"\n",
    "    elif ask < 1000000:\n",
    "        return \"500000-1000000\"\n",
    "    elif ask < 5000000:\n",
    "        return \"1M-5M\"\n",
    "    elif ask < 10000000:\n",
    "        return \"5M-10M\"\n",
    "    elif ask < 50000000:\n",
    "        return \"10M-50M\"\n",
    "    else:\n",
    "        return \"50M+\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a80da462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ask(ask):\n",
    "    if ask < 9999:\n",
    "        return 1 #return 9_999 // 5000\n",
    "    elif ask < 24999:\n",
    "        return 2 #return 24_999 // 5000\n",
    "    elif ask < 99999:\n",
    "        return 3 #return 99_999 // 5000\n",
    "    elif ask < 499999:\n",
    "        return 4 #return 499_999 // 5000\n",
    "    elif ask < 1000000:\n",
    "        return 5 #return 1_000_000 // 5000\n",
    "    elif ask < 5000000:\n",
    "        return 6 #return 5_000_000 // 5000\n",
    "    elif ask < 10000000:\n",
    "        return 7 #return 10_000_000 // 5000\n",
    "    elif ask < 50000000:\n",
    "        return 8 #return 50_000_000 // 5000\n",
    "    else:\n",
    "        return 9 #return 100_000_000 // 5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82033d",
   "metadata": {},
   "source": [
    "### More fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9516f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjile\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged df.shape()=(34299, 39)\n",
      "nins=39\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 340)               13600     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 340)               115940    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 170)               57970     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 40)                3440      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 243,686\n",
      "Trainable params: 243,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.6105 - accuracy: 0.6981\n",
      "Epoch 2/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5882 - accuracy: 0.7195\n",
      "Epoch 3/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5921 - accuracy: 0.7154\n",
      "Epoch 4/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5899 - accuracy: 0.7181\n",
      "Epoch 5/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5925 - accuracy: 0.7182\n",
      "\n",
      "Epoch 00005: saving model to checkpoints_opt\\weights_2.05.hdf5\n",
      "Epoch 6/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5939 - accuracy: 0.7177\n",
      "Epoch 7/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5932 - accuracy: 0.7171\n",
      "Epoch 8/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5990 - accuracy: 0.7129\n",
      "Epoch 9/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5973 - accuracy: 0.7124\n",
      "Epoch 10/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5970 - accuracy: 0.7126\n",
      "\n",
      "Epoch 00010: saving model to checkpoints_opt\\weights_2.10.hdf5\n",
      "Epoch 11/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5976 - accuracy: 0.7122\n",
      "Epoch 12/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5986 - accuracy: 0.7105\n",
      "Epoch 13/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.6610 - accuracy: 0.6182\n",
      "Epoch 14/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.6432 - accuracy: 0.6445\n",
      "Epoch 15/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.6021 - accuracy: 0.7100\n",
      "\n",
      "Epoch 00015: saving model to checkpoints_opt\\weights_2.15.hdf5\n",
      "Epoch 16/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.6029 - accuracy: 0.7095\n",
      "Epoch 17/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.6015 - accuracy: 0.7103\n",
      "Epoch 18/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.6084 - accuracy: 0.6964\n",
      "Epoch 19/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.6140 - accuracy: 0.6874\n",
      "Epoch 20/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.6043 - accuracy: 0.6981\n",
      "\n",
      "Epoch 00020: saving model to checkpoints_opt\\weights_2.20.hdf5\n",
      "Epoch 21/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5916 - accuracy: 0.7123\n",
      "Epoch 22/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5859 - accuracy: 0.7198\n",
      "Epoch 23/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5831 - accuracy: 0.7211\n",
      "Epoch 24/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5817 - accuracy: 0.7255\n",
      "Epoch 25/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5794 - accuracy: 0.7237\n",
      "\n",
      "Epoch 00025: saving model to checkpoints_opt\\weights_2.25.hdf5\n",
      "Epoch 26/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5799 - accuracy: 0.7213\n",
      "Epoch 27/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5803 - accuracy: 0.7230\n",
      "Epoch 28/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5769 - accuracy: 0.7249\n",
      "Epoch 29/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5758 - accuracy: 0.7258\n",
      "Epoch 30/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5779 - accuracy: 0.7241\n",
      "\n",
      "Epoch 00030: saving model to checkpoints_opt\\weights_2.30.hdf5\n",
      "Epoch 31/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5750 - accuracy: 0.7281\n",
      "Epoch 32/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5751 - accuracy: 0.7274\n",
      "Epoch 33/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5744 - accuracy: 0.7264\n",
      "Epoch 34/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5743 - accuracy: 0.7257\n",
      "Epoch 35/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5753 - accuracy: 0.7256\n",
      "\n",
      "Epoch 00035: saving model to checkpoints_opt\\weights_2.35.hdf5\n",
      "Epoch 36/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5747 - accuracy: 0.7274\n",
      "Epoch 37/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5741 - accuracy: 0.7271\n",
      "Epoch 38/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5748 - accuracy: 0.7256\n",
      "Epoch 39/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5741 - accuracy: 0.7267\n",
      "Epoch 40/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5743 - accuracy: 0.7247\n",
      "\n",
      "Epoch 00040: saving model to checkpoints_opt\\weights_2.40.hdf5\n",
      "Epoch 41/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5738 - accuracy: 0.7251\n",
      "Epoch 42/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5734 - accuracy: 0.7269\n",
      "Epoch 43/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5719 - accuracy: 0.7285\n",
      "Epoch 44/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5704 - accuracy: 0.7289\n",
      "Epoch 45/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5672 - accuracy: 0.7283\n",
      "\n",
      "Epoch 00045: saving model to checkpoints_opt\\weights_2.45.hdf5\n",
      "Epoch 46/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5691 - accuracy: 0.7268\n",
      "Epoch 47/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5690 - accuracy: 0.7273\n",
      "Epoch 48/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5679 - accuracy: 0.7263\n",
      "Epoch 49/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5641 - accuracy: 0.7293\n",
      "Epoch 50/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5627 - accuracy: 0.7309\n",
      "\n",
      "Epoch 00050: saving model to checkpoints_opt\\weights_2.50.hdf5\n",
      "Epoch 51/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5613 - accuracy: 0.7298\n",
      "Epoch 52/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5626 - accuracy: 0.7296\n",
      "Epoch 53/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5636 - accuracy: 0.7294\n",
      "Epoch 54/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5620 - accuracy: 0.7283\n",
      "Epoch 55/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5624 - accuracy: 0.7291\n",
      "\n",
      "Epoch 00055: saving model to checkpoints_opt\\weights_2.55.hdf5\n",
      "Epoch 56/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5658 - accuracy: 0.7300\n",
      "Epoch 57/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5674 - accuracy: 0.7264\n",
      "Epoch 58/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5649 - accuracy: 0.7296\n",
      "Epoch 59/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5627 - accuracy: 0.7309\n",
      "Epoch 60/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5648 - accuracy: 0.7265\n",
      "\n",
      "Epoch 00060: saving model to checkpoints_opt\\weights_2.60.hdf5\n",
      "Epoch 61/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5619 - accuracy: 0.7276\n",
      "Epoch 62/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5621 - accuracy: 0.7302\n",
      "Epoch 63/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5569 - accuracy: 0.7305\n",
      "Epoch 64/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5568 - accuracy: 0.7292\n",
      "Epoch 65/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5577 - accuracy: 0.7288\n",
      "\n",
      "Epoch 00065: saving model to checkpoints_opt\\weights_2.65.hdf5\n",
      "Epoch 66/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5553 - accuracy: 0.7291\n",
      "Epoch 67/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5532 - accuracy: 0.7287\n",
      "Epoch 68/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5568 - accuracy: 0.7292\n",
      "Epoch 69/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5607 - accuracy: 0.7299\n",
      "Epoch 70/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5551 - accuracy: 0.7298\n",
      "\n",
      "Epoch 00070: saving model to checkpoints_opt\\weights_2.70.hdf5\n",
      "Epoch 71/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5541 - accuracy: 0.7283\n",
      "Epoch 72/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5521 - accuracy: 0.7290\n",
      "Epoch 73/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5519 - accuracy: 0.7263\n",
      "Epoch 74/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5520 - accuracy: 0.7289\n",
      "Epoch 75/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5507 - accuracy: 0.7303\n",
      "\n",
      "Epoch 00075: saving model to checkpoints_opt\\weights_2.75.hdf5\n",
      "Epoch 76/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5525 - accuracy: 0.7308\n",
      "Epoch 77/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5520 - accuracy: 0.7303\n",
      "Epoch 78/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5508 - accuracy: 0.7290\n",
      "Epoch 79/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5522 - accuracy: 0.7318\n",
      "Epoch 80/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5519 - accuracy: 0.7296\n",
      "\n",
      "Epoch 00080: saving model to checkpoints_opt\\weights_2.80.hdf5\n",
      "Epoch 81/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5523 - accuracy: 0.7320\n",
      "Epoch 82/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5517 - accuracy: 0.7299\n",
      "Epoch 83/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5521 - accuracy: 0.7306\n",
      "Epoch 84/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5563 - accuracy: 0.7253\n",
      "Epoch 85/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5560 - accuracy: 0.7276\n",
      "\n",
      "Epoch 00085: saving model to checkpoints_opt\\weights_2.85.hdf5\n",
      "Epoch 86/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5545 - accuracy: 0.7288\n",
      "Epoch 87/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5527 - accuracy: 0.7299\n",
      "Epoch 88/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5508 - accuracy: 0.7303\n",
      "Epoch 89/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5502 - accuracy: 0.7309\n",
      "Epoch 90/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5497 - accuracy: 0.7318\n",
      "\n",
      "Epoch 00090: saving model to checkpoints_opt\\weights_2.90.hdf5\n",
      "Epoch 91/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5506 - accuracy: 0.7312\n",
      "Epoch 92/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5496 - accuracy: 0.7310\n",
      "Epoch 93/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5502 - accuracy: 0.7313\n",
      "Epoch 94/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5517 - accuracy: 0.7287\n",
      "Epoch 95/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5527 - accuracy: 0.7304\n",
      "\n",
      "Epoch 00095: saving model to checkpoints_opt\\weights_2.95.hdf5\n",
      "Epoch 96/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5505 - accuracy: 0.7317\n",
      "Epoch 97/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5513 - accuracy: 0.7320\n",
      "Epoch 98/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5497 - accuracy: 0.7310\n",
      "Epoch 99/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5485 - accuracy: 0.7320\n",
      "Epoch 100/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5492 - accuracy: 0.7327\n",
      "\n",
      "Epoch 00100: saving model to checkpoints_opt\\weights_2.100.hdf5\n",
      "Epoch 101/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5483 - accuracy: 0.7339\n",
      "Epoch 102/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5503 - accuracy: 0.7331\n",
      "Epoch 103/1500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5511 - accuracy: 0.7312\n",
      "Epoch 104/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5513 - accuracy: 0.7316\n",
      "Epoch 105/1500\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5496 - accuracy: 0.7331\n",
      "\n",
      "Epoch 00105: saving model to checkpoints_opt\\weights_2.105.hdf5\n",
      "Epoch 106/1500\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5509 - accuracy: 0.7327\n",
      "Epoch 107/1500\n",
      "585/804 [====================>.........] - ETA: 0s - loss: 0.5504 - accuracy: 0.7293"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5f58b53537de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;33m{\u001b[0m\u001b[1;34m'units'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;34m'act'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m ])\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mtrained_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_nn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"checkpoints_opt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# Evaluate the model using the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a9d2da9952e0>\u001b[0m in \u001b[0;36mtrain_nn_model\u001b[1;34m(model, X_train, y_train, n_epochs, checkpoint_dir)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#save_freq='epoch')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mfit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcp_callback_opt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "csv_cols = [\n",
    "    'EIN', \n",
    "    'NAME', \n",
    "    'APPLICATION_TYPE', \n",
    "    'AFFILIATION', \n",
    "    'CLASSIFICATION', \n",
    "    'USE_CASE', \n",
    "    'ORGANIZATION', \n",
    "    'STATUS', \n",
    "    'INCOME_AMT', \n",
    "    'SPECIAL_CONSIDERATIONS', \n",
    "    'ASK_AMT', \n",
    "    'IS_SUCCESSFUL'\n",
    "]\n",
    "application_df.drop(columns=[\n",
    "    'EIN', 'NAME','INCOME_AMT','SPECIAL_CONSIDERATIONS','STATUS'\n",
    "    ], inplace=True)\n",
    "\n",
    "reduce_count_vals(application_df, 'APPLICATION_TYPE', 500)\n",
    "reduce_count_vals(application_df, 'CLASSIFICATION', 1500)\n",
    "\n",
    "#application_df[\"INCOME_AMT\"] = application_df[\"INCOME_AMT\"].apply(range_to_int)\n",
    "#application_df[\"ASK_AMT\"] = application_df[\"ASK_AMT\"].apply(encode_ask)\n",
    "application_df[\"ASK_AMT\"] = application_df[\"ASK_AMT\"].apply(chunk_ask)\n",
    "\n",
    "application_df, X, y = do_one_hot(application_df, 'IS_SUCCESSFUL')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "X_train_scaled, X_test_scaled = do_scale(StandardScaler())\n",
    "#X_train_scaled, X_test_scaled = do_scale(MinMaxScaler())\n",
    "\n",
    "nins = application_df.shape[1]\n",
    "print(f\"nins={nins}\")\n",
    "nn_model = build_model(inputs=nins, layers=[\n",
    "    {'units': 340, 'act': 'tanh'},\n",
    "    {'units': 340, 'act': 'tanh'},\n",
    "    {'units': 170, 'act': 'tanh'},\n",
    "    {'units': 170, 'act': 'tanh'},\n",
    "    {'units': 85,  'act': 'tanh'},\n",
    "    {'units': 40,  'act': 'relu'},\n",
    "    {'units': 40,  'act': 'relu'},\n",
    "    {'units': 40,  'act': 'relu'},\n",
    "    {'units': 40,  'act': 'relu'},\n",
    "    {'units': 40,  'act': 'relu'},\n",
    "    {'units': 40,  'act': 'relu'},\n",
    "    {'units': 20,  'act': 'sigmoid'},\n",
    "    {'units': 5,   'act': 'sigmoid'},\n",
    "    {'units': 1,   'act': 'sigmoid'}\n",
    "])\n",
    "trained_model = train_nn_model(nn_model, X_train_scaled, y_train, n_epochs=1500, checkpoint_dir=\"checkpoints_opt\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Export our model to HDF5 file\n",
    "nn_model.save(\"AlphabetSoupCharity_opt4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#application_df  = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "#application_df.drop(columns=['EIN', 'NAME'], inplace=True)\n",
    "#do_scatter_plots(application_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa906f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                        int64\n",
       "NAME                      object\n",
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "987fde3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                       34299\n",
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "STATUS                        2\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "ASK_AMT                    8747\n",
       "IS_SUCCESSFUL                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec53216b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                       34299\n",
       "NAME                      19568\n",
       "APPLICATION_TYPE             17\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION               71\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "STATUS                        2\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "ASK_AMT                       9\n",
       "IS_SUCCESSFUL                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df[\"ASK_AMT\"] = application_df[\"ASK_AMT\"].apply(chunk_ask)\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a20d29e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                       34299\n",
       "NAME                      19568\n",
       "APPLICATION_TYPE              9\n",
       "AFFILIATION                   6\n",
       "CLASSIFICATION                6\n",
       "USE_CASE                      5\n",
       "ORGANIZATION                  4\n",
       "STATUS                        2\n",
       "INCOME_AMT                    9\n",
       "SPECIAL_CONSIDERATIONS        2\n",
       "ASK_AMT                       9\n",
       "IS_SUCCESSFUL                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_count_vals(application_df, 'APPLICATION_TYPE', 500)\n",
    "reduce_count_vals(application_df, 'CLASSIFICATION', 1500)\n",
    "application_df.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
