{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c97deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34bfae8",
   "metadata": {},
   "source": [
    "### Define functions for use during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c26c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_count_vals(df, colname, threshold):\n",
    "    # Determine which values to replace if counts are less than ...?\n",
    "    counts = df[colname].value_counts()\n",
    "    replace_list = list(counts[counts < threshold].index)\n",
    "\n",
    "    # Replace in dataframe\n",
    "    for item in replace_list:\n",
    "       df[colname] = df[colname].replace(item,\"Other\")\n",
    "    \n",
    "    # Check to make sure binning was successful\n",
    "    df[colname].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6966a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_hot(df, y_col):\n",
    "    # Create a list of columns that are 'object' type\n",
    "    obj_cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "    # Create a OneHotEncoder instance\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    # Fit and transform the OneHotEncoder using the categorical variable list\n",
    "    encode_df = pd.DataFrame(enc.fit_transform(df[obj_cat]))\n",
    "    # Add the encoded variable names to the DataFrame\n",
    "    encode_df.columns = enc.get_feature_names(obj_cat)\n",
    "    \n",
    "    # Merge one-hot encoded features and drop the originals\n",
    "    df = df.merge(encode_df, left_index=True, right_index=True)\n",
    "    df = df.drop(obj_cat,1)\n",
    "    \n",
    "    # Split our preprocessed data into our features and target arrays\n",
    "    y = df[y_col].values\n",
    "    df.drop(columns=[y_col], inplace=True)\n",
    "    X = df.values\n",
    "    print(f\"merged df.shape()={df.shape}\")\n",
    "    \n",
    "    return df, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaebfc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_scatter_plots(df):\n",
    "    for xx in ['APPLICATION_TYPE', \n",
    "        'AFFILIATION', \n",
    "        'CLASSIFICATION', \n",
    "        'USE_CASE', \n",
    "        'ORGANIZATION', \n",
    "        'INCOME_AMT', \n",
    "              ]:\n",
    "        for yy in ['APPLICATION_TYPE', \n",
    "            'AFFILIATION', \n",
    "            'CLASSIFICATION', \n",
    "            'USE_CASE', \n",
    "            'ORGANIZATION', \n",
    "            'INCOME_AMT'\n",
    "                  ]:\n",
    "            if xx == yy:\n",
    "                continue\n",
    "            titlestring = f\"x={xx} vs. y={yy}\"\n",
    "            df.plot.scatter(x=xx, y=yy, title=titlestring, c='IS_SUCCESSFUL', colormap='winter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db688177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_scale(scaler):\n",
    "    # Scale the data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d6a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, layers):\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    first = True\n",
    "    for layer in layers:\n",
    "        if first:\n",
    "            first = False\n",
    "            nn.add(tf.keras.layers.Dense(units=layer['units'], activation=layer['act'], input_dim=inputs))\n",
    "        else:\n",
    "            nn.add(tf.keras.layers.Dense(units=layer['units'], activation=layer['act']))\n",
    "\n",
    "    print(nn.summary())\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160cdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_model(model, X_train, y_train, n_epochs, checkpoint_dir):\n",
    "    # Create a callback that saves the model's weights every epoch\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    \n",
    "    # Define the checkpoint path and filenames\n",
    "    os.makedirs(\"checkpoints_opt\",exist_ok=True)\n",
    "    #checkpoint_file = f\"weights.{epoch:02d}.hdf5\"\n",
    "    #checkpoint_path = f\"checkpoints_opt/weights.{epoch:02d}.hdf5\"\n",
    "    checkpoint_path = \"checkpoints_opt/weights_2.{epoch:02d}.hdf5\"\n",
    "    \n",
    "    cp_callback_opt = ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        period=5)\n",
    "\n",
    "    # Normally we use 'save_freq', but it behaves strangely, and I could not get\n",
    "    # it to save every 5 epochs. The 'period' param is now deprecated, but it works.\n",
    "        #save_freq='epoch')\n",
    "        \n",
    "    fit_model = model.fit(X_train, y_train, epochs=n_epochs, callbacks=[cp_callback_opt])\n",
    "    return fit_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73b59c",
   "metadata": {},
   "source": [
    "### Optimation Run 1 - With 7 layers of tanh & sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f31c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged df.shape()=(34299, 43)\n",
      "nins=43\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 340)               14960     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 170)               57970     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                3440      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 91,836\n",
      "Trainable params: 91,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjile\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5924 - accuracy: 0.7132\n",
      "Epoch 2/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5672 - accuracy: 0.7293\n",
      "Epoch 3/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5603 - accuracy: 0.7294\n",
      "Epoch 4/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5567 - accuracy: 0.7306\n",
      "Epoch 5/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5538 - accuracy: 0.7313\n",
      "\n",
      "Epoch 00005: saving model to checkpoints_opt\\weights_2.05.hdf5\n",
      "Epoch 6/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5531 - accuracy: 0.7310\n",
      "Epoch 7/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5505 - accuracy: 0.7332\n",
      "Epoch 8/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5511 - accuracy: 0.7323\n",
      "Epoch 9/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5493 - accuracy: 0.7320\n",
      "Epoch 10/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.7342\n",
      "\n",
      "Epoch 00010: saving model to checkpoints_opt\\weights_2.10.hdf5\n",
      "Epoch 11/500\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5471 - accuracy: 0.7345\n",
      "Epoch 12/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5474 - accuracy: 0.7332\n",
      "Epoch 13/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5471 - accuracy: 0.7349\n",
      "Epoch 14/500\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5452 - accuracy: 0.7354\n",
      "Epoch 15/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5454 - accuracy: 0.7343\n",
      "\n",
      "Epoch 00015: saving model to checkpoints_opt\\weights_2.15.hdf5\n",
      "Epoch 16/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5450 - accuracy: 0.7352\n",
      "Epoch 17/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7355\n",
      "Epoch 18/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5432 - accuracy: 0.7363\n",
      "Epoch 19/500\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5426 - accuracy: 0.7362\n",
      "Epoch 20/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7369\n",
      "\n",
      "Epoch 00020: saving model to checkpoints_opt\\weights_2.20.hdf5\n",
      "Epoch 21/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7377\n",
      "Epoch 22/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7367\n",
      "Epoch 23/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7374\n",
      "Epoch 24/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5406 - accuracy: 0.7379\n",
      "Epoch 25/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.7375\n",
      "\n",
      "Epoch 00025: saving model to checkpoints_opt\\weights_2.25.hdf5\n",
      "Epoch 26/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5411 - accuracy: 0.7370\n",
      "Epoch 27/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5414 - accuracy: 0.7383\n",
      "Epoch 28/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.7371\n",
      "Epoch 29/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5408 - accuracy: 0.7371\n",
      "Epoch 30/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7376\n",
      "\n",
      "Epoch 00030: saving model to checkpoints_opt\\weights_2.30.hdf5\n",
      "Epoch 31/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.7385\n",
      "Epoch 32/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7382\n",
      "Epoch 33/500\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5397 - accuracy: 0.7393\n",
      "Epoch 34/500\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5401 - accuracy: 0.7373\n",
      "Epoch 35/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7392\n",
      "\n",
      "Epoch 00035: saving model to checkpoints_opt\\weights_2.35.hdf5\n",
      "Epoch 36/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7395\n",
      "Epoch 37/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5388 - accuracy: 0.7381\n",
      "Epoch 38/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7383\n",
      "Epoch 39/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7386\n",
      "Epoch 40/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7397\n",
      "\n",
      "Epoch 00040: saving model to checkpoints_opt\\weights_2.40.hdf5\n",
      "Epoch 41/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5370 - accuracy: 0.7398\n",
      "Epoch 42/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5377 - accuracy: 0.7393\n",
      "Epoch 43/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7391\n",
      "Epoch 44/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.7388\n",
      "Epoch 45/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5375 - accuracy: 0.7402\n",
      "\n",
      "Epoch 00045: saving model to checkpoints_opt\\weights_2.45.hdf5\n",
      "Epoch 46/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7396\n",
      "Epoch 47/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5373 - accuracy: 0.7386\n",
      "Epoch 48/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5372 - accuracy: 0.7395\n",
      "Epoch 49/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 50/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7397\n",
      "\n",
      "Epoch 00050: saving model to checkpoints_opt\\weights_2.50.hdf5\n",
      "Epoch 51/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7406\n",
      "Epoch 52/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7394\n",
      "Epoch 53/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5365 - accuracy: 0.7400\n",
      "Epoch 54/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5363 - accuracy: 0.7395\n",
      "Epoch 55/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7400\n",
      "\n",
      "Epoch 00055: saving model to checkpoints_opt\\weights_2.55.hdf5\n",
      "Epoch 56/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7397\n",
      "Epoch 57/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.7402\n",
      "Epoch 58/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7395\n",
      "Epoch 59/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7407\n",
      "Epoch 60/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.7399\n",
      "\n",
      "Epoch 00060: saving model to checkpoints_opt\\weights_2.60.hdf5\n",
      "Epoch 61/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5361 - accuracy: 0.7385\n",
      "Epoch 62/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5358 - accuracy: 0.7392\n",
      "Epoch 63/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7402\n",
      "Epoch 64/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7404\n",
      "Epoch 65/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7402\n",
      "\n",
      "Epoch 00065: saving model to checkpoints_opt\\weights_2.65.hdf5\n",
      "Epoch 66/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7413\n",
      "Epoch 67/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5359 - accuracy: 0.7399\n",
      "Epoch 68/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5361 - accuracy: 0.7400\n",
      "Epoch 69/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.7405\n",
      "Epoch 70/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7405\n",
      "\n",
      "Epoch 00070: saving model to checkpoints_opt\\weights_2.70.hdf5\n",
      "Epoch 71/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5350 - accuracy: 0.7402\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7414\n",
      "Epoch 73/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5357 - accuracy: 0.7407\n",
      "Epoch 74/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7401\n",
      "Epoch 75/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7410\n",
      "\n",
      "Epoch 00075: saving model to checkpoints_opt\\weights_2.75.hdf5\n",
      "Epoch 76/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7410\n",
      "Epoch 77/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7411\n",
      "Epoch 78/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7405\n",
      "Epoch 79/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.7410\n",
      "Epoch 80/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.7411\n",
      "\n",
      "Epoch 00080: saving model to checkpoints_opt\\weights_2.80.hdf5\n",
      "Epoch 81/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7409\n",
      "Epoch 82/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7411\n",
      "Epoch 83/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5345 - accuracy: 0.7412\n",
      "Epoch 84/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5350 - accuracy: 0.7419\n",
      "Epoch 85/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7408\n",
      "\n",
      "Epoch 00085: saving model to checkpoints_opt\\weights_2.85.hdf5\n",
      "Epoch 86/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7414\n",
      "Epoch 87/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7416\n",
      "Epoch 88/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7412\n",
      "Epoch 89/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7409\n",
      "Epoch 90/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.7416\n",
      "\n",
      "Epoch 00090: saving model to checkpoints_opt\\weights_2.90.hdf5\n",
      "Epoch 91/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.7406\n",
      "Epoch 92/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5345 - accuracy: 0.7406\n",
      "Epoch 93/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7405\n",
      "Epoch 94/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5340 - accuracy: 0.7420\n",
      "Epoch 95/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5360 - accuracy: 0.7398\n",
      "\n",
      "Epoch 00095: saving model to checkpoints_opt\\weights_2.95.hdf5\n",
      "Epoch 96/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5348 - accuracy: 0.7414\n",
      "Epoch 97/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5348 - accuracy: 0.7411\n",
      "Epoch 98/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5339 - accuracy: 0.7404\n",
      "Epoch 99/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7413\n",
      "Epoch 100/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7418\n",
      "\n",
      "Epoch 00100: saving model to checkpoints_opt\\weights_2.100.hdf5\n",
      "Epoch 101/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.7415\n",
      "Epoch 102/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.7409\n",
      "Epoch 103/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.7416\n",
      "Epoch 104/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7416\n",
      "Epoch 105/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7417\n",
      "\n",
      "Epoch 00105: saving model to checkpoints_opt\\weights_2.105.hdf5\n",
      "Epoch 106/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7406\n",
      "Epoch 107/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5347 - accuracy: 0.7410\n",
      "Epoch 108/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5341 - accuracy: 0.7411\n",
      "Epoch 109/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7422\n",
      "Epoch 110/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.7407\n",
      "\n",
      "Epoch 00110: saving model to checkpoints_opt\\weights_2.110.hdf5\n",
      "Epoch 111/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5344 - accuracy: 0.7404\n",
      "Epoch 112/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5333 - accuracy: 0.7418\n",
      "Epoch 113/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7416\n",
      "Epoch 114/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7415\n",
      "Epoch 115/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5338 - accuracy: 0.7414\n",
      "\n",
      "Epoch 00115: saving model to checkpoints_opt\\weights_2.115.hdf5\n",
      "Epoch 116/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7416\n",
      "Epoch 117/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7420\n",
      "Epoch 118/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7421\n",
      "Epoch 119/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7402\n",
      "Epoch 120/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7425\n",
      "\n",
      "Epoch 00120: saving model to checkpoints_opt\\weights_2.120.hdf5\n",
      "Epoch 121/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7413\n",
      "Epoch 122/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7418\n",
      "Epoch 123/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5334 - accuracy: 0.7419\n",
      "Epoch 124/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5337 - accuracy: 0.7418\n",
      "Epoch 125/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5337 - accuracy: 0.7413\n",
      "\n",
      "Epoch 00125: saving model to checkpoints_opt\\weights_2.125.hdf5\n",
      "Epoch 126/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5336 - accuracy: 0.7414\n",
      "Epoch 127/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5333 - accuracy: 0.7416\n",
      "Epoch 128/500\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5337 - accuracy: 0.7406\n",
      "Epoch 129/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5339 - accuracy: 0.7410\n",
      "Epoch 130/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5335 - accuracy: 0.7415\n",
      "\n",
      "Epoch 00130: saving model to checkpoints_opt\\weights_2.130.hdf5\n",
      "Epoch 131/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7411\n",
      "Epoch 132/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7406\n",
      "Epoch 133/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7406\n",
      "Epoch 134/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5340 - accuracy: 0.7413\n",
      "Epoch 135/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7418\n",
      "\n",
      "Epoch 00135: saving model to checkpoints_opt\\weights_2.135.hdf5\n",
      "Epoch 136/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5327 - accuracy: 0.7419\n",
      "Epoch 137/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7407\n",
      "Epoch 138/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7411\n",
      "Epoch 139/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.7415\n",
      "Epoch 140/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7408\n",
      "\n",
      "Epoch 00140: saving model to checkpoints_opt\\weights_2.140.hdf5\n",
      "Epoch 141/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7426\n",
      "Epoch 142/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7417\n",
      "Epoch 143/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7420\n",
      "Epoch 144/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.7419\n",
      "Epoch 145/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7423\n",
      "\n",
      "Epoch 00145: saving model to checkpoints_opt\\weights_2.145.hdf5\n",
      "Epoch 146/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5334 - accuracy: 0.7417\n",
      "Epoch 147/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7422\n",
      "Epoch 148/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7419\n",
      "Epoch 149/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5325 - accuracy: 0.7426\n",
      "Epoch 150/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7416\n",
      "\n",
      "Epoch 00150: saving model to checkpoints_opt\\weights_2.150.hdf5\n",
      "Epoch 151/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7422\n",
      "Epoch 152/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7415\n",
      "Epoch 153/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.7416\n",
      "Epoch 154/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5330 - accuracy: 0.7417\n",
      "Epoch 155/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5331 - accuracy: 0.7412\n",
      "\n",
      "Epoch 00155: saving model to checkpoints_opt\\weights_2.155.hdf5\n",
      "Epoch 156/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5332 - accuracy: 0.7417\n",
      "Epoch 157/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7421\n",
      "Epoch 158/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5331 - accuracy: 0.7418\n",
      "Epoch 159/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7416\n",
      "Epoch 160/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7401\n",
      "\n",
      "Epoch 00160: saving model to checkpoints_opt\\weights_2.160.hdf5\n",
      "Epoch 161/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5333 - accuracy: 0.7411\n",
      "Epoch 162/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5338 - accuracy: 0.7421\n",
      "Epoch 163/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.7421\n",
      "Epoch 164/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5331 - accuracy: 0.7416\n",
      "Epoch 165/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7415\n",
      "\n",
      "Epoch 00165: saving model to checkpoints_opt\\weights_2.165.hdf5\n",
      "Epoch 166/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.7423\n",
      "Epoch 167/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5322 - accuracy: 0.7422\n",
      "Epoch 168/500\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5326 - accuracy: 0.7419\n",
      "Epoch 169/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7413\n",
      "Epoch 170/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.7413\n",
      "\n",
      "Epoch 00170: saving model to checkpoints_opt\\weights_2.170.hdf5\n",
      "Epoch 171/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7409\n",
      "Epoch 172/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7416\n",
      "Epoch 173/500\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7423\n",
      "Epoch 174/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5328 - accuracy: 0.7419\n",
      "Epoch 175/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.7406\n",
      "\n",
      "Epoch 00175: saving model to checkpoints_opt\\weights_2.175.hdf5\n",
      "Epoch 176/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.7408\n",
      "Epoch 177/500\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7411\n",
      "Epoch 178/500\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7418\n",
      "Epoch 179/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5326 - accuracy: 0.7426\n",
      "Epoch 180/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.7417\n",
      "\n",
      "Epoch 00180: saving model to checkpoints_opt\\weights_2.180.hdf5\n",
      "Epoch 181/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.7424\n",
      "Epoch 182/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7425\n",
      "Epoch 183/500\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.7412\n",
      "Epoch 184/500\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5326 - accuracy: 0.7423\n",
      "Epoch 185/500\n",
      "347/804 [===========>..................] - ETA: 1s - loss: 0.5291 - accuracy: 0.7436"
     ]
    }
   ],
   "source": [
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "csv_cols = [\n",
    "    'EIN', \n",
    "    'NAME', \n",
    "    'APPLICATION_TYPE', \n",
    "    'AFFILIATION', \n",
    "    'CLASSIFICATION', \n",
    "    'USE_CASE', \n",
    "    'ORGANIZATION', \n",
    "    'STATUS', \n",
    "    'INCOME_AMT', \n",
    "    'SPECIAL_CONSIDERATIONS', \n",
    "    'ASK_AMT', \n",
    "    'IS_SUCCESSFUL'\n",
    "]\n",
    "application_df.drop(columns=['EIN', 'NAME'], inplace=True)\n",
    "\n",
    "reduce_count_vals(application_df, 'APPLICATION_TYPE', 500)\n",
    "reduce_count_vals(application_df, 'CLASSIFICATION', 1500)\n",
    "\n",
    "application_df, X, y = do_one_hot(application_df, 'IS_SUCCESSFUL')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "X_train_scaled, X_test_scaled = do_scale(StandardScaler())\n",
    "#X_train_scaled, X_test_scaled = do_scale(MinMaxScaler())\n",
    "\n",
    "nins = application_df.shape[1]\n",
    "print(f\"nins={nins}\")\n",
    "nn_model = build_model(inputs=nins, layers=[\n",
    "    {'units': 340, 'act': 'tanh'},\n",
    "    {'units': 170, 'act': 'tanh'},\n",
    "    {'units': 85,  'act': 'tanh'},\n",
    "    {'units': 40,  'act': 'tanh'},\n",
    "    {'units': 20,  'act': 'sigmoid'},\n",
    "    {'units': 5,   'act': 'sigmoid'},\n",
    "    {'units': 1,   'act': 'sigmoid'}\n",
    "])\n",
    "trained_model = train_nn_model(nn_model, X_train_scaled, y_train, n_epochs=500, checkpoint_dir=\"checkpoints_opt\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Export our model to HDF5 file\n",
    "nn_model.save(\"AlphabetSoupCharity_opt1.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193f4e0",
   "metadata": {},
   "source": [
    "### Optimization Run 2 - Same as Run1, but drop 'STATUS' & 'SPECIAL_CONSIDERATIONS'; and bucketize 'AFFILIATION', 'ORGANIZATION', AND 'INCOME_AMT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67457394",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "csv_cols = [\n",
    "    'EIN', \n",
    "    'NAME', \n",
    "    'APPLICATION_TYPE', \n",
    "    'AFFILIATION', \n",
    "    'CLASSIFICATION', \n",
    "    'USE_CASE', \n",
    "    'ORGANIZATION', \n",
    "    'STATUS', \n",
    "    'INCOME_AMT', \n",
    "    'SPECIAL_CONSIDERATIONS', \n",
    "    'ASK_AMT', \n",
    "    'IS_SUCCESSFUL'\n",
    "]\n",
    "\n",
    "application_df.drop(columns=['EIN', 'NAME','STATUS', 'SPECIAL_CONSIDERATIONS'], inplace=True)\n",
    "\n",
    "reduce_count_vals(application_df, 'APPLICATION_TYPE', 500)\n",
    "reduce_count_vals(application_df, 'CLASSIFICATION', 1500)\n",
    "reduce_count_vals(application_df, 'AFFILIATION', 100)\n",
    "reduce_count_vals(application_df, 'ORGANIZATION', 500)\n",
    "reduce_count_vals(application_df, 'INCOME_AMT', 500)\n",
    "\n",
    "application_df, X, y = do_one_hot(application_df, 'IS_SUCCESSFUL')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "#X_train_scaled, X_test_scaled = do_scale(StandardScaler())\n",
    "X_train_scaled, X_test_scaled = do_scale(MinMaxScaler())\n",
    "\n",
    "nins = application_df.shape[1]\n",
    "print(f\"nins={nins}\")\n",
    "nn_model = build_model(inputs=nins, layers=[\n",
    "    {'units': 340, 'act': 'relu'},\n",
    "    {'units': 170, 'act': 'relu'},\n",
    "    {'units': 85,  'act': 'relu'},\n",
    "    {'units': 40,  'act': 'relu'},\n",
    "    {'units': 20,  'act': 'sigmoid'},\n",
    "    {'units': 5,   'act': 'sigmoid'},\n",
    "    {'units': 1,   'act': 'sigmoid'}\n",
    "])\n",
    "trained_model = train_nn_model(nn_model, X_train_scaled, y_train, n_epochs=500, checkpoint_dir=\"checkpoints_opt\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Export our model to HDF5 file\n",
    "nn_model.save(\"AlphabetSoupCharity_opt2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9addc93",
   "metadata": {},
   "source": [
    "### Optimization Run 3 - with KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "\n",
    "def create_tuner_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=70,\n",
    "        max_value=140,\n",
    "        step=10), activation=activation, input_dim=40))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for ii in range(hp.Int('num_layers', 1, 10)):\n",
    "        #nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(ii),\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(ii),                                             \n",
    "            min_value=70,\n",
    "            max_value=140,\n",
    "            step=10),\n",
    "            activation=activation))\n",
    "            \n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_keras_tuner(X_train, y_train, n_epochs, validation_data):\n",
    "    # Create a `Hyperband()` tuner instance\n",
    "    tuner = kt.Hyperband(\n",
    "        create_tuner_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_epochs=50,\n",
    "        hyperband_iterations=2,\n",
    "        overwrite=True)\n",
    "\n",
    "    # Run the kerastuner search for best hyperparameters\n",
    "    tuner.search(X_train, y_train, epochs=n_epochs, validation_data=validation_data)\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "csv_cols = [\n",
    "    'EIN', \n",
    "    'NAME', \n",
    "    'APPLICATION_TYPE', \n",
    "    'AFFILIATION', \n",
    "    'CLASSIFICATION', \n",
    "    'USE_CASE', \n",
    "    'ORGANIZATION', \n",
    "    'STATUS', \n",
    "    'INCOME_AMT', \n",
    "    'SPECIAL_CONSIDERATIONS', \n",
    "    'ASK_AMT', \n",
    "    'IS_SUCCESSFUL'\n",
    "]\n",
    "\n",
    "application_df.drop(columns=['EIN', 'NAME','STATUS', 'SPECIAL_CONSIDERATIONS'], inplace=True)\n",
    "\n",
    "reduce_count_vals(application_df, 'APPLICATION_TYPE', 500)\n",
    "reduce_count_vals(application_df, 'CLASSIFICATION', 1500)\n",
    "\n",
    "application_df, X, y = do_one_hot(application_df, 'IS_SUCCESSFUL')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "X_train_scaled, X_test_scaled = do_scale(StandardScaler())\n",
    "#X_train_scaled, X_test_scaled = do_scale(MinMaxScaler())\n",
    "\n",
    "nins = application_df.shape[1]\n",
    "print(f\"nins={nins}\")\n",
    "\n",
    "tuner = run_keras_tuner(X_train_scaled, y_train, n_epochs=20, validation_data=(X_test_scaled,y_test))\n",
    "\n",
    "# # Evaluate the model using the test data\n",
    "# model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# Export our model to HDF5 file\n",
    "nn_model.save(\"AlphabetSoupCharity_opt3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f883b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 3 model hyperparameters and print the values\n",
    "best_hypers = []\n",
    "for ii in range(1,4):\n",
    "    best_hyper = tuner.get_best_hyperparameters(ii)[0]\n",
    "    print(best_hyper.values)\n",
    "    best_hypers.append(best_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41858314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the top 3 models against the test dataset\n",
    "best_models = []\n",
    "for ii in range(1,4):\n",
    "    best_model = tuner.get_best_models(ii)[0]\n",
    "    model_loss, model_accuracy = best_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "    best_models.append(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
